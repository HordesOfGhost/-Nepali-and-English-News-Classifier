{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import wordnet\n",
    "from langdetect import detect\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Summarize:\n",
    "    def __init__(self,paragraph):\n",
    "        self.vec=TfidfVectorizer()\n",
    "        self.vec.fit_transform([paragraph])\n",
    "        self.col=self.vec.get_feature_names_out()\n",
    "        self.paragraph=paragraph\n",
    "        self.language=detect(self.paragraph)\n",
    "        if detect(self.language) != \"en\":\n",
    "            #stop_words\n",
    "            self.stop_words=open(\"stopwords.txt\",\"r\",encoding=\"utf-8\")\n",
    "            self.stop_words=self.stop_words.read()\n",
    "            self.stop_words=self.stop_words.split(\"\\n\")\n",
    "            \n",
    "            #num file\n",
    "            self.nepali_num=open(\"numbers.txt\",\"r\",encoding=\"utf-8\")\n",
    "            self.nepali_num=self.nepali_num.read()\n",
    "            self.nepali_num=self.nepali_num.split(\",\")\n",
    "            \n",
    "            #suffix file\n",
    "            self.nepali_suffix=open(\"suffix.txt\",\"r\",encoding=\"utf-8\")\n",
    "            self.nepali_suffix=self.nepali_suffix.read()\n",
    "            self.nepali_suffix=self.nepali_suffix.split(\"\\n\")\n",
    "    \n",
    "    def nepali_process_paragraph(self):\n",
    "        paragraph=str(self.paragraph)\n",
    "        \n",
    "        #removing \\n and \\ufeff\n",
    "        remove=['\\n','\\ufeff']\n",
    "        for i in remove:\n",
    "            paragraph.replace(i,'')\n",
    "        \n",
    "        #read stop words\n",
    "        #Remove Stop Words\n",
    "        #word_tokens = Tokenizer().word_tokenize(text)\n",
    "        word_tokens = paragraph.split(\" \")\n",
    "        filtered_list = [w for w in word_tokens if not w in self.stop_words]\n",
    "        \n",
    "        #Remove Nepali numbers\n",
    "        num_filter=[]\n",
    "        for i in range(0,len(filtered_list)):\n",
    "            for j in range(0,len(self.nepali_num)):\n",
    "                if self.nepali_num[j] in filtered_list[i]:\n",
    "                    num_filter.append(filtered_list[i])\n",
    "                    break\n",
    "        for filter in num_filter:\n",
    "            filtered_list.remove(filter)\n",
    "        \n",
    "        #Remove English numbers\n",
    "        num=['0','1','2','3','4','5','6','7','8','9']\n",
    "        num_filter=[]\n",
    "        for i in range(0,len(filtered_list)):\n",
    "            for j in range(0,len(num)):\n",
    "                if num[j] in filtered_list[i]:\n",
    "                    num_filter.append(filtered_list[i])\n",
    "                    break\n",
    "        for filter in num_filter:\n",
    "            filtered_list.remove(filter)\n",
    "        stemmed_string=' '.join(filtered_list)\n",
    "        \n",
    "        return stemmed_string\n",
    "            \n",
    "    def english_process_paragraph(self):\n",
    "        paragraph=str(self.paragraph)\n",
    "        #lowercasing\n",
    "        paragraph=paragraph.lower()\n",
    "        #Remove Stop Words\n",
    "        stop_words=set(stopwords.words('english'))\n",
    "        word_tokens = word_tokenize(paragraph)\n",
    "        filtered_list = [w for w in word_tokens if not w in stop_words]\n",
    "        \n",
    "        \n",
    "        #Remove numbers and special Symbols\n",
    "        #words like 100m 2m were not removed so using this\n",
    "        num=['0','1','2','3','4','5','6','7','8','9']\n",
    "        num_filter=[]\n",
    "        for i in range(0,len(filtered_list)):\n",
    "            for j in range(0,len(num)):\n",
    "                if num[j] in filtered_list[i]:\n",
    "                    num_filter.append(filtered_list[i])\n",
    "                    break\n",
    "        \n",
    "        for filter in num_filter:\n",
    "            filtered_list.remove(filter)\n",
    "                    \n",
    "        filtered_list = [w for w in filtered_list if w.isalnum()]\n",
    "        \n",
    "        #Lematizing\n",
    "        wordnet_lemmatizer=WordNetLemmatizer()\n",
    "        lemmatized_list=[wordnet_lemmatizer.lemmatize(w,wordnet.VERB) for w in filtered_list]\n",
    "        lemmatized_string=' '.join(lemmatized_list)\n",
    "        \n",
    "        return lemmatized_string\n",
    "    \n",
    "    def calc_idf(self):\n",
    "        doc_count=len(self.paragraph)\n",
    "        df={}\n",
    "        idf={}\n",
    "        for char in self.col:\n",
    "            df[char]=0\n",
    "            idf[char]=0\n",
    "        #Calculating df\n",
    "        for i in range(0,len(self.col)):\n",
    "            for j in range(0,len(self.paragraph)):\n",
    "                if self.col[i] in self.paragraph[j]:\n",
    "                    df[self.col[i]]+=1\n",
    "        #Calculating idf\n",
    "        for char in self.col:\n",
    "            idf[char]=math.log((doc_count+1)/(1+df[char]))+1\n",
    "        return(idf)\n",
    "    \n",
    "    def calc_tf_idf(self,sentence):\n",
    "        idf=self.calc_idf()\n",
    "        \n",
    "        tf_idf={}\n",
    "        word_count={}\n",
    "        \n",
    "        for ch in self.col:\n",
    "            tf_idf[ch]=0\n",
    "            word_count[ch]=0\n",
    "        #Calculating tf\n",
    "        words = sentence.split()\n",
    "        for ch in words:\n",
    "            if ch in self.col:\n",
    "                if ch in word_count:\n",
    "                    word_count[ch] += 1\n",
    "                else:\n",
    "                    word_count[ch] = 1\n",
    "    \n",
    "        rough_tfidf=list(self.col)\n",
    "        for keys in word_count.keys():\n",
    "            tf_idf[keys]=idf[keys]*word_count[keys]\n",
    "            if keys in rough_tfidf:\n",
    "                index=rough_tfidf.index(keys)\n",
    "                rough_tfidf[index]=tf_idf[keys]\n",
    "        norm=0\n",
    "        for i in range(0,len(rough_tfidf)):\n",
    "            norm+=rough_tfidf[i]**2\n",
    "        if norm==0:\n",
    "            norm=1\n",
    "        for i in range(0,len(rough_tfidf)):\n",
    "            rough_tfidf[i]=round(rough_tfidf[i]/math.sqrt(norm),8)\n",
    "        return rough_tfidf\n",
    "    \n",
    "    def count_sentence_eng(self):\n",
    "        cnt=self.paragraph.count(\".\")+1\n",
    "        return cnt\n",
    "    def count_sentence_nep(self):\n",
    "        cnt=self.paragraph.count(\"।\")+1\n",
    "        return cnt\n",
    "    def count_summarized(self,summarized):\n",
    "        cnt=summarized.count(\"||\")+1\n",
    "        return cnt\n",
    "    \n",
    "    def sentence_number(self,number):\n",
    "        paragraph=self.paragraph\n",
    "        \n",
    "        if self.language==\"en\":\n",
    "            processed_paragraph=self.english_process_paragraph()\n",
    "            each_sentence=paragraph.split(\".\")\n",
    "            each_sentence.remove(\"\")\n",
    "            sentence_count=self.count_sentence_eng()\n",
    "        else:\n",
    "            processed_paragraph=self.nepali_process_paragraph()\n",
    "            #paragraph=paragraph.replace(\"।\",\"|\")\n",
    "            each_sentence=paragraph.split(\"।\")\n",
    "            each_sentence.remove(\"\")\n",
    "            sentence_count=self.count_sentence_nep()\n",
    "            \n",
    "        \n",
    "        if (number>sentence_count):\n",
    "            print(\"ERROR: Summarization line exceeds total sentence count\")\n",
    "        \n",
    "        else:\n",
    "            #Each sentence tf_idf\n",
    "            each_tfidf=[]\n",
    "            tf_idf_score=[]\n",
    "            for i in range(len(each_sentence)):\n",
    "                each_tfidf.append(self.calc_tf_idf(each_sentence[i]))\n",
    "            for i in range(len(each_tfidf)):\n",
    "                each_tfidf[i]=np.array(each_tfidf[i])\n",
    "                tf_idf_score.append(each_tfidf[i].sum())\n",
    "            \n",
    "            tf_idf_score=sorted(tf_idf_score)\n",
    "            print(tf_idf_score)\n",
    "            selection=tf_idf_score[-number:]\n",
    "            \n",
    "            summarized=\"\"\n",
    "            for i in range(sentence_count-1):\n",
    "                for j in range(len(selection)-1,-1,-1):\n",
    "                    if selection[j]==tf_idf_score[i]:\n",
    "                        summarized += each_sentence[i]\n",
    "                        summarized += \"||\"\n",
    "                        break\n",
    "                if self.count_summarized(summarized)==number+1:\n",
    "                    break\n",
    "                           \n",
    "            return summarized \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SummarizeCheck:\n",
    "    def __init__(self,paragraph):\n",
    "        self.vec=TfidfVectorizer()\n",
    "        self.vec.fit_transform([paragraph])\n",
    "        self.col=self.vec.get_feature_names_out()\n",
    "        self.paragraph=paragraph\n",
    "        self.language=detect(self.paragraph)\n",
    "        if detect(self.language) != \"en\":\n",
    "            #stop_words\n",
    "            self.stop_words=open(\"stopwords.txt\",\"r\",encoding=\"utf-8\")\n",
    "            self.stop_words=self.stop_words.read()\n",
    "            self.stop_words=self.stop_words.split(\"\\n\")\n",
    "            \n",
    "            #num file\n",
    "            self.nepali_num=open(\"numbers.txt\",\"r\",encoding=\"utf-8\")\n",
    "            self.nepali_num=self.nepali_num.read()\n",
    "            self.nepali_num=self.nepali_num.split(\",\")\n",
    "            \n",
    "            #suffix file\n",
    "            self.nepali_suffix=open(\"suffix.txt\",\"r\",encoding=\"utf-8\")\n",
    "            self.nepali_suffix=self.nepali_suffix.read()\n",
    "            self.nepali_suffix=self.nepali_suffix.split(\"\\n\")\n",
    "    \n",
    "    def nepali_process_paragraph(self):\n",
    "        paragraph=str(self.paragraph)\n",
    "        \n",
    "        #removing \\n and \\ufeff\n",
    "        remove=['\\n','\\ufeff']\n",
    "        for i in remove:\n",
    "            paragraph.replace(i,'')\n",
    "        \n",
    "        #read stop words\n",
    "        #Remove Stop Words\n",
    "        #word_tokens = Tokenizer().word_tokenize(text)\n",
    "        word_tokens = paragraph.split(\" \")\n",
    "        filtered_list = [w for w in word_tokens if not w in self.stop_words]\n",
    "        \n",
    "        #Remove Nepali numbers\n",
    "        num_filter=[]\n",
    "        for i in range(0,len(filtered_list)):\n",
    "            for j in range(0,len(self.nepali_num)):\n",
    "                if self.nepali_num[j] in filtered_list[i]:\n",
    "                    num_filter.append(filtered_list[i])\n",
    "                    break\n",
    "        for filter in num_filter:\n",
    "            filtered_list.remove(filter)\n",
    "        \n",
    "        #Remove English numbers\n",
    "        num=['0','1','2','3','4','5','6','7','8','9']\n",
    "        num_filter=[]\n",
    "        for i in range(0,len(filtered_list)):\n",
    "            for j in range(0,len(num)):\n",
    "                if num[j] in filtered_list[i]:\n",
    "                    num_filter.append(filtered_list[i])\n",
    "                    break\n",
    "        for filter in num_filter:\n",
    "            filtered_list.remove(filter)\n",
    "        stemmed_string=' '.join(filtered_list)\n",
    "        \n",
    "        return stemmed_string\n",
    "            \n",
    "    def english_process_paragraph(self):\n",
    "        paragraph=str(self.paragraph)\n",
    "        #lowercasing\n",
    "        paragraph=paragraph.lower()\n",
    "        #Remove Stop Words\n",
    "        stop_words=set(stopwords.words('english'))\n",
    "        word_tokens = word_tokenize(paragraph)\n",
    "        filtered_list = [w for w in word_tokens if not w in stop_words]\n",
    "        \n",
    "        \n",
    "        #Remove numbers and special Symbols\n",
    "        #words like 100m 2m were not removed so using this\n",
    "        num=['0','1','2','3','4','5','6','7','8','9']\n",
    "        num_filter=[]\n",
    "        for i in range(0,len(filtered_list)):\n",
    "            for j in range(0,len(num)):\n",
    "                if num[j] in filtered_list[i]:\n",
    "                    num_filter.append(filtered_list[i])\n",
    "                    break\n",
    "        \n",
    "        for filter in num_filter:\n",
    "            filtered_list.remove(filter)\n",
    "                    \n",
    "        filtered_list = [w for w in filtered_list if w.isalnum()]\n",
    "        \n",
    "        #Lematizing\n",
    "        wordnet_lemmatizer=WordNetLemmatizer()\n",
    "        lemmatized_list=[wordnet_lemmatizer.lemmatize(w,wordnet.VERB) for w in filtered_list]\n",
    "        lemmatized_string=' '.join(lemmatized_list)\n",
    "        \n",
    "        return lemmatized_string\n",
    "    \n",
    "    def calc_idf(self):\n",
    "        doc_count=len(self.paragraph)\n",
    "        df={}\n",
    "        idf={}\n",
    "        for char in self.col:\n",
    "            df[char]=0\n",
    "            idf[char]=0\n",
    "        #Calculating df\n",
    "        for i in range(0,len(self.col)):\n",
    "            for j in range(0,len(self.paragraph)):\n",
    "                if self.col[i] in self.paragraph[j]:\n",
    "                    df[self.col[i]]+=1\n",
    "        #Calculating idf\n",
    "        for char in self.col:\n",
    "            idf[char]=math.log((doc_count+1)/(1+df[char]))+1\n",
    "        #print(idf)\n",
    "        #print(len(idf))\n",
    "        #print(\"\\n \\n \\n \\n\")\n",
    "        #print(idf)\n",
    "        return(idf)\n",
    "    \n",
    "    def calc_tf_idf(self,sentence):\n",
    "        idf=self.calc_idf()\n",
    "        \n",
    "        tf_idf={}\n",
    "        word_count={}\n",
    "        '''\n",
    "        for ch in self.col:\n",
    "            tf_idf[ch]=0\n",
    "            word_count[ch]=0\n",
    "        #Calculating tf\n",
    "        words = sentence.split()\n",
    "        for ch in words:\n",
    "            if ch in self.col:\n",
    "                if ch in word_count:\n",
    "                    word_count[ch] += 1\n",
    "                else:\n",
    "                    word_count[ch] = 1'''\n",
    "        for i in range(len(sentence)):\n",
    "            for t in sentence[i].split():\n",
    "                if t not in word_count.keys():\n",
    "                    word_count[t] = 1\n",
    "                else:\n",
    "                    word_count[t] +=1\n",
    "    \n",
    "        rough_tfidf=list(self.col)\n",
    "        for keys in word_count.keys():\n",
    "            tf_idf[keys]=idf[keys]*word_count[keys]\n",
    "            if keys in rough_tfidf:\n",
    "                index=rough_tfidf.index(keys)\n",
    "                rough_tfidf[index]=tf_idf[keys]\n",
    "        norm=0\n",
    "        for i in range(0,len(rough_tfidf)):\n",
    "            norm+=rough_tfidf[i]**2\n",
    "        if norm==0:\n",
    "            norm=1\n",
    "        for i in range(0,len(rough_tfidf)):\n",
    "            rough_tfidf[i]=round(rough_tfidf[i]/math.sqrt(norm),8)\n",
    "        return rough_tfidf\n",
    "    \n",
    "    def count_sentence_eng(self):\n",
    "        cnt=self.paragraph.count(\".\")+1\n",
    "        return cnt\n",
    "    def count_sentence_nep(self):\n",
    "        cnt=self.paragraph.count(\"।\")+1\n",
    "        return cnt\n",
    "    def count_summarized(self,summarized):\n",
    "        cnt=summarized.count(\"||\")+1\n",
    "        return cnt\n",
    "    \n",
    "    def sentence_number(self,number):\n",
    "        paragraph=self.paragraph\n",
    "        \n",
    "        if self.language==\"en\":\n",
    "            processed_paragraph=self.english_process_paragraph()\n",
    "            each_sentence=paragraph.split(\".\")\n",
    "            each_sentence.remove(\"\")\n",
    "            sentence_count=self.count_sentence_eng()\n",
    "        else:\n",
    "            processed_paragraph=self.nepali_process_paragraph()\n",
    "            paragraph=paragraph.replace(\"।\",\"|\")\n",
    "            each_sentence=paragraph.split(\"|\")\n",
    "            each_sentence.remove(\"\")\n",
    "            sentence_count=self.count_sentence_nep()\n",
    "            \n",
    "        \n",
    "        if (number>sentence_count):\n",
    "            print(\"ERROR: Summarization line exceeds total sentence count\")\n",
    "        \n",
    "        else:\n",
    "            #Each sentence tf_idf\n",
    "            each_tfidf=[]\n",
    "            tf_idf_score=[]\n",
    "            for i in range(len(each_sentence)):\n",
    "                each_tfidf.append(self.calc_tf_idf(each_sentence[i]))\n",
    "            for i in range(len(each_tfidf)):\n",
    "                each_tfidf[i]=np.array(each_tfidf[i])\n",
    "                tf_idf_score.append(each_tfidf[i].sum())\n",
    "            \n",
    "            tf_idf_score=sorted(tf_idf_score)\n",
    "            print(tf_idf_score)\n",
    "            selection=tf_idf_score[-number:]\n",
    "            loopsteps = len(selection) - number\n",
    "            j = len(selection) - 1 \n",
    "            summarized=\"\"\n",
    "            for i in range(sentence_count-1):\n",
    "                while j > loopsteps:\n",
    "                    if selection[j]==tf_idf_score[i]:\n",
    "                        summarized += each_sentence[i]\n",
    "                        summarized += \"||\"\n",
    "                        break\n",
    "                    j -= 1           \n",
    "            return summarized \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "textnep=\"होवार्ड स्नूकर खेल्न आक्रोशित कन्जरभेटिभ नेता माइकल होवार्डले स्नूकर हलमा आफ्ना स्कूलका साथीहरूसँग समय बिताउन ट्रन्ट खेल्ने गरेको स्वीकार गरेका छन्। श्री होवार्डले भने कि 1950 को दशकमा लानेलीको ज्याक स्नूकर हलमा उनको समयले उनलाई कुनै दिगो नोक्सान पुर्याएन। तर उनले टाइम्स शैक्षिक सप्लिमेन्टलाई भने कि ट्र्यान्सी धेरै नराम्रो थियो र दृढ कार्य आवश्यक छ भने। मिस्टर होवर्डले ओ-लेभल र थप कक्षाकोठा अनुशासनमा फर्कन पनि आह्वान गरे। मिस्टर हावर्डले अन्ततः क्याम्ब्रिज विश्वविद्यालय जान लानेली व्याकरण स्कूल र स्नूकर हल छोडे। उसले भन्यो: मलाई लाग्दैन कि यसले मलाई कुनै दिगो नोक्सान गरेको छ। न त यसले मलाई स्नूकर विश्व च्याम्पियन बनाएको छ। हामी दिउँसो छिट्टै निस्किदा केही अवसरहरू भएका हुन सक्छन्। म केवल इमानदार छु। मलाई लाग्छ कि ट्र्यान्सी एक धेरै नराम्रो कुरा हो र यसको सामना गर्न दृढ कदम चाल्नु पर्छ। स्नूकरको विश्व च्याम्पियनसिप जित्न असफल भएका अर्को खेलाडी - जिमी द व्हर्लविन्ड ह्वाइट -ले पहिले आफ्नो दिन धुवाँदार हलहरूमा बिताउनको सट्टा पाठ हराएको स्वीकार गरेका छन्। टोनी मेयो [अर्को खेलाडी] र म हाम्रो सबै खाली समय त्यहाँ बिताउन गर्थ्यौं श्री ह्वाइटले भने कि हामी खेल र वातावरण मन पराउँछौं। विद्यालय झ्यालबाट बाहिर गयो । म केही समयको लागि गएँ र त्यसपछि समय लिन थाले। मिस्टर हावर्डको फेलो वेल्शम्यान रे रीर्डन - जसलाई उनका साथी पेशेवरहरू ड्र्याकुला भनेर चिनिन्छन् - स्नूकर विश्व च्याम्पियनशिप छ पटक जितेका थिए जसले १४ वर्षको उमेरमा स्कूल छोडेर खानीको रूपमा काम गरे। र ल्यानेलीका मिस्टर होवार्ड जस्ता टेरी ग्रिफिथले सन् १९७९ मा प्रतियोगिता जितेका थिए। यी दुईबीच ज्याक एसमा कहिले भिडन्त भएको थियो वा थिएन भन्ने थाहा छैन।\"\n",
    "texteng=\"howard  truanted to play snooker  conservative leader michael howard has admitted he used to play truant to spend time with his school friends at a snooker hall.  mr howard said his time at jack s snooker hall in llanelli in the 1950s had not done him  any lasting damage . but he told the times educational supplement that truancy was  very bad  and said  firm action  was needed. mr howard also called for a return to o-levels and more classroom discipline.  mr howard eventually left llanelli grammar school - and the snooker hall - to go to cambridge university. he said:  i don t think it s done me any lasting damage. nor has it made me a snooker world champion.  there might have been some occasions when we left early of an afternoon.   i m just being honest. i think truancy is a very bad thing and that firm action should be taken to deal with it.  another player who has failed to win snooker s world championship - jimmy  the whirlwind   white - has previously admitted missing lessons  instead spending his days in smoky halls.  tony meo [another player] and me used to spend all of our spare time there   mr white said   we loved the game and the atmosphere.  school went out of the window. i went for a while and then started taking time off.  mr howard s fellow welshman ray reardon - known by his fellow professionals as  dracula  - won the snooker world championship six times  having left school at 14 to work as a miner. and terry griffiths  like mr howard from llanelli  won the tournament in 1979. it is not known whether the two of them ever clashed cues at jack s.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "texteng2=\"china had role in yukos split-up china lent russia $6bn (Â£3.2bn) to help the russian government renationalise the key yuganskneftegas unit of oil group yukos  it has been revealed.  the kremlin said on tuesday that the $6bn which russian state bank veb lent state-owned rosneft to help buy yugansk in turn came from chinese banks. the revelation came as the russian government said rosneft had signed a long-term oil supply deal with china. the deal sees rosneft receive $6bn in credits from china s cnpc.  according to russian newspaper vedomosti  these credits would be used to pay off the loans rosneft received to finance the purchase of yugansk. reports said cnpc had been offered 20% of yugansk in return for providing finance but the company opted for a long-term oil supply deal instead. analysts said one factor that might have influenced the chinese decision was the possibility of litigation from yukos  yugansk s former owner  if cnpc had become a shareholder. rosneft and veb declined to comment.  the two companies [rosneft and cnpc] have agreed on the pre-payment for long-term deliveries   said russian oil official sergei oganesyan.  there is nothing unusual that the pre-payment is for five to six years.   the announcements help to explain how rosneft  a medium-sized  indebted  and relatively unknown firm  was able to finance its surprise purchase of yugansk. yugansk was sold for $9.3bn in an auction last year to help yukos pay off part of a $27bn bill in unpaid taxes and fines.  the embattled russian oil giant had previously filed for bankruptcy protection in a us court in an attempt to prevent the forced sale of its main production arm. but yugansk was sold to a little known shell company which in turn was bought by rosneft. yukos claims its downfall was punishment for the political ambitions of its founder mikhail khodorkovsky. once the country s richest man  mr khodorkovsky is on trial for fraud and tax evasion.  the deal between rosneft and cnpc is seen as part of china s desire to secure long-term oil supplies to feed its booming economy. china s thirst for products such as crude oil  copper and steel has helped pushed global commodity prices to record levels.  clearly the chinese are trying to get some leverage [in russia]   said dmitry lukashov  an analyst at brokerage aton.  they understand property rights in russia are not the most important rights  and they are more interested in guaranteeing supplies.   if the price of oil is fixed under the deal  which is unlikely  it could be very profitable for the chinese   mr lukashov continued.  and rosneft is in desperate need of cash  so it s a good deal for them too.\"\n",
    "textnep2=\"युकोस विभाजनमा चीनको भूमिका रहेको थियो, चीनले रुसी सरकारलाई तेल समूह युकोसको प्रमुख युगान्स्कनेफ्तेगास एकाइलाई पुनः राष्ट्रियकरण गर्न मद्दत गर्न रुसलाई ६ अर्ब डलर (£३.२ बिलियन) ऋण दिएको खुलासा भएको छ । क्रेमलिनले मंगलबार भन्यो कि रुसी स्टेट बैंक भेबले युगान्स्क किन्न मद्दत गर्न सरकारी स्वामित्वको रोजनेफ्टलाई 6 बिलियन डलर चिनियाँ बैंकहरूबाट आएको हो। रुसी सरकारले रोस्नेफ्टले चीनसँग दीर्घकालीन तेल आपूर्ति सम्झौतामा हस्ताक्षर गरेको भन्दै यो खुलासा भएको हो। सम्झौताले रोस्नेफ्टले चीनको सीएनपीसीबाट $ 6 बिलियन क्रेडिट प्राप्त गरेको देख्छ। रुसी अखबार वेदोमोस्तीका अनुसार यी क्रेडिटहरू रोसनेफ्टले युगान्स्कको खरिदका लागि प्राप्त गरेको ऋण तिर्न प्रयोग गरिने छ। रिपोर्टहरूका अनुसार सीएनपीसीलाई वित्त प्रदान गर्न बदलामा युगान्स्कको २०% प्रस्ताव गरिएको थियो तर कम्पनीले यसको सट्टा दीर्घकालीन तेल आपूर्ति सम्झौताको लागि रोजेको थियो। विश्लेषकहरूले चिनियाँ निर्णयलाई प्रभाव पार्ने एउटा कारक युकोस युगान्स्कको पूर्व मालिक सीएनपीसी सेयरहोल्डर भएको खण्डमा मुद्दा चलाउने सम्भावना रहेको बताए। rosneft र veb टिप्पणी गर्न अस्वीकार गरे। दुई कम्पनीहरू [rosneft र cnpc] लामो अवधिको डेलिभरीको लागि पूर्व भुक्तानीमा सहमत भएको रूसी तेल अधिकारी सर्गेई ओगानेसियानले बताए। पूर्व-भुक्तानी पाँच देखि छ वर्षको लागि हो भन्ने असामान्य केही छैन। घोषणाहरूले कसरी मध्यम आकारको ऋणी र अपेक्षाकृत अज्ञात फर्मले युगान्स्कको आफ्नो अचम्मको खरीदलाई वित्त पोषण गर्न सक्षम भयो भनेर व्याख्या गर्न मद्दत गर्दछ। गत वर्ष एक लिलामीमा yugansk $ 9.3 बिलियनमा बेचेको थियो जसले युकोहरूलाई नतिरेको कर र जरिवानामा $ 27 बिलियन बिलको अंश तिर्न मद्दत गर्दछ। द्वन्द्वग्रस्त रूसी तेल दिग्गजले पहिले आफ्नो मुख्य उत्पादन हातको जबरजस्ती बिक्री रोक्न प्रयासमा अमेरिकी अदालतमा दिवालियापन सुरक्षाको लागि दायर गरेको थियो। तर युगान्स्क थोरै ज्ञात शेल कम्पनीलाई बेचेको थियो जुन फलस्वरूप रोजनेफ्टले किनेको थियो। युकोसले यसको पतन यसको संस्थापक मिखाइल खोडोरकोभस्कीको राजनीतिक महत्वाकांक्षाको लागि सजाय भएको दाबी गर्दछ। एक पटक देशको सबैभन्दा धनी व्यक्ति मिस्टर खोडोरकोभस्की ठगी र कर छलीको लागि मुद्दामा छन्। रोस्नेफ्ट र सीएनपीसी बीचको सम्झौतालाई चीनको बढ्दो अर्थतन्त्रलाई खुवाउन दीर्घकालीन तेल आपूर्ति सुरक्षित गर्ने इच्छाको अंशको रूपमा हेरिएको छ। कच्चा तेल तामा र स्टिल जस्ता उत्पादनहरूका लागि चीनको तिर्खाले विश्वव्यापी वस्तुको मूल्यलाई रेकर्ड स्तरमा धकेल्न मद्दत गरेको छ। ब्रोकरेज एटोनका विश्लेषक दिमित्री लुकाशोभले स्पष्ट रूपमा चिनियाँहरूले [रूसमा] केही फाइदा लिन खोजिरहेका छन्। तिनीहरू बुझ्छन् रसियामा सम्पत्ति अधिकारहरू सबैभन्दा महत्त्वपूर्ण अधिकारहरू होइनन् र तिनीहरू आपूर्तिको ग्यारेन्टीमा बढी चासो राख्छन्। यदि यो सम्झौता अन्तर्गत तेलको मूल्य निर्धारण गरिएको छ जुन असम्भव छ यो चिनियाँ श्री लुकाशोभको लागि धेरै लाभदायक हुन सक्छ। र रोस्नेफ्टलाई नगदको असाध्यै आवश्यकता छ त्यसैले यो उनीहरूको लागि पनि राम्रो सम्झौता हो।\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Summarize(textnep).count_sentence_nep())\n",
    "Summarize(texteng).count_sentence_eng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.41421356, 1.41421356, 1.41421356]\n",
      " मिस्टर हावर्डको फेलो वेल्शम्यान रे रीर्डन - जसलाई उनका साथी पेशेवरहरू ड्र्याकुला भनेर चिनिन्छन् - स्नूकर विश्व च्याम्पियनशिप छ पटक जितेका थिए जसले १४ वर्षको उमेरमा स्कूल छोडेर खानीको रूपमा काम गरे||\n",
      "[1.73205081, 2.44948974, 2.82842712, 2.9999999699999993, 2.99999997, 3.31662474, 3.6055512999999997, 3.6055512999999997, 3.74165736, 3.77123616, 4.0249224, 4.12310571, 4.21775692, 4.37880262, 4.42635207, 4.91353823, 5.04825212]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' it is not known whether the two of them ever clashed cues at jack s||'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Summarize(textnep).sentence_number(1))\n",
    "Summarize(texteng).sentence_number(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "होवार्ड स्नूकर खेल्न आक्रोशित कन्जरभेटिभ नेता माइकल होवार्डले स्नूकर हलमा आफ्ना स्कूलका साथीहरूसँग समय बिताउन ट्रन्ट खेल्ने गरेको स्वीकार गरेका छन्। श्री होवार्डले भने कि 1950 को दशकमा लानेलीको ज्याक स्नूकर हलमा उनको समयले उनलाई कुनै दिगो नोक्सान पुर्याएन। तर उनले टाइम्स शैक्षिक सप्लिमेन्टलाई भने कि ट्र्यान्सी धेरै नराम्रो थियो र दृढ कार्य आवश्यक छ भने। मिस्टर होवर्डले ओ-लेभल र थप कक्षाकोठा अनुशासनमा फर्कन पनि आह्वान गरे। मिस्टर हावर्डले अन्ततः क्याम्ब्रिज विश्वविद्यालय जान लानेली व्याकरण स्कूल र स्नूकर हल छोडे। उसले भन्यो: मलाई लाग्दैन कि यसले मलाई कुनै दिगो नोक्सान गरेको छ। न त यसले मलाई स्नूकर विश्व च्याम्पियन बनाएको छ। हामी दिउँसो छिट्टै निस्किदा केही अवसरहरू भएका हुन सक्छन्। म केवल इमानदार छु। मलाई लाग्छ कि ट्र्यान्सी एक धेरै नराम्रो कुरा हो र यसको सामना गर्न दृढ कदम चाल्नु पर्छ। स्नूकरको विश्व च्याम्पियनसिप जित्न असफल भएका अर्को खेलाडी - जिमी द व्हर्लविन्ड ह्वाइट -ले पहिले आफ्नो दिन धुवाँदार हलहरूमा बिताउनको सट्टा पाठ हराएको स्वीकार गरेका छन्। टोनी मेयो [अर्को खेलाडी] र म हाम्रो सबै खाली समय त्यहाँ बिताउन गर्थ्यौं श्री ह्वाइटले भने कि हामी खेल र वातावरण मन पराउँछौं। विद्यालय झ्यालबाट बाहिर गयो । म केही समयको लागि गएँ र त्यसपछि समय लिन थाले। मिस्टर हावर्डको फेलो वेल्शम्यान रे रीर्डन - जसलाई उनका साथी पेशेवरहरू ड्र्याकुला भनेर चिनिन्छन् - स्नूकर विश्व च्याम्पियनशिप छ पटक जितेका थिए जसले १४ वर्षको उमेरमा स्कूल छोडेर खानीको रूपमा काम गरे। र ल्यानेलीका मिस्टर होवार्ड जस्ता टेरी ग्रिफिथले सन् १९७९ मा प्रतियोगिता जितेका थिए। यी दुईबीच ज्याक एसमा कहिले भिडन्त भएको थियो वा थिएन भन्ने थाहा छैन।\n"
     ]
    }
   ],
   "source": [
    "textnep=\"होवार्ड स्नूकर खेल्न आक्रोशित कन्जरभेटिभ नेता माइकल होवार्डले स्नूकर हलमा आफ्ना स्कूलका साथीहरूसँग समय बिताउन ट्रन्ट खेल्ने गरेको स्वीकार गरेका छन्। श्री होवार्डले भने कि 1950 को दशकमा लानेलीको ज्याक स्नूकर हलमा उनको समयले उनलाई कुनै दिगो नोक्सान पुर्याएन। तर उनले टाइम्स शैक्षिक सप्लिमेन्टलाई भने कि ट्र्यान्सी धेरै नराम्रो थियो र दृढ कार्य आवश्यक छ भने। मिस्टर होवर्डले ओ-लेभल र थप कक्षाकोठा अनुशासनमा फर्कन पनि आह्वान गरे। मिस्टर हावर्डले अन्ततः क्याम्ब्रिज विश्वविद्यालय जान लानेली व्याकरण स्कूल र स्नूकर हल छोडे। उसले भन्यो: मलाई लाग्दैन कि यसले मलाई कुनै दिगो नोक्सान गरेको छ। न त यसले मलाई स्नूकर विश्व च्याम्पियन बनाएको छ। हामी दिउँसो छिट्टै निस्किदा केही अवसरहरू भएका हुन सक्छन्। म केवल इमानदार छु। मलाई लाग्छ कि ट्र्यान्सी एक धेरै नराम्रो कुरा हो र यसको सामना गर्न दृढ कदम चाल्नु पर्छ। स्नूकरको विश्व च्याम्पियनसिप जित्न असफल भएका अर्को खेलाडी - जिमी द व्हर्लविन्ड ह्वाइट -ले पहिले आफ्नो दिन धुवाँदार हलहरूमा बिताउनको सट्टा पाठ हराएको स्वीकार गरेका छन्। टोनी मेयो [अर्को खेलाडी] र म हाम्रो सबै खाली समय त्यहाँ बिताउन गर्थ्यौं श्री ह्वाइटले भने कि हामी खेल र वातावरण मन पराउँछौं। विद्यालय झ्यालबाट बाहिर गयो । म केही समयको लागि गएँ र त्यसपछि समय लिन थाले। मिस्टर हावर्डको फेलो वेल्शम्यान रे रीर्डन - जसलाई उनका साथी पेशेवरहरू ड्र्याकुला भनेर चिनिन्छन् - स्नूकर विश्व च्याम्पियनशिप छ पटक जितेका थिए जसले १४ वर्षको उमेरमा स्कूल छोडेर खानीको रूपमा काम गरे। र ल्यानेलीका मिस्टर होवार्ड जस्ता टेरी ग्रिफिथले सन् १९७९ मा प्रतियोगिता जितेका थिए। यी दुईबीच ज्याक एसमा कहिले भिडन्त भएको थियो वा थिएन भन्ने थाहा छैन।\"\n",
    "print(textnep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ह'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[139], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(SummarizeCheck(textnep)\u001b[39m.\u001b[39;49msentence_number(\u001b[39m1\u001b[39;49m))\n\u001b[0;32m      2\u001b[0m SummarizeCheck(texteng)\u001b[39m.\u001b[39msentence_number(\u001b[39m1\u001b[39m)\n",
      "Cell \u001b[1;32mIn[133], line 188\u001b[0m, in \u001b[0;36mSummarizeCheck.sentence_number\u001b[1;34m(self, number)\u001b[0m\n\u001b[0;32m    186\u001b[0m tf_idf_score\u001b[39m=\u001b[39m[]\n\u001b[0;32m    187\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(each_sentence)):\n\u001b[1;32m--> 188\u001b[0m     each_tfidf\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcalc_tf_idf(each_sentence[i]))\n\u001b[0;32m    189\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(each_tfidf)):\n\u001b[0;32m    190\u001b[0m     each_tfidf[i]\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39marray(each_tfidf[i])\n",
      "Cell \u001b[1;32mIn[133], line 141\u001b[0m, in \u001b[0;36mSummarizeCheck.calc_tf_idf\u001b[1;34m(self, sentence)\u001b[0m\n\u001b[0;32m    139\u001b[0m rough_tfidf\u001b[39m=\u001b[39m\u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcol)\n\u001b[0;32m    140\u001b[0m \u001b[39mfor\u001b[39;00m keys \u001b[39min\u001b[39;00m word_count\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m--> 141\u001b[0m     tf_idf[keys]\u001b[39m=\u001b[39midf[keys]\u001b[39m*\u001b[39mword_count[keys]\n\u001b[0;32m    142\u001b[0m     \u001b[39mif\u001b[39;00m keys \u001b[39min\u001b[39;00m rough_tfidf:\n\u001b[0;32m    143\u001b[0m         index\u001b[39m=\u001b[39mrough_tfidf\u001b[39m.\u001b[39mindex(keys)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'ह'"
     ]
    }
   ],
   "source": [
    "print(SummarizeCheck(textnep).sentence_number(1))\n",
    "SummarizeCheck(texteng).sentence_number(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Summarize(texteng2).count_sentence_eng())\n",
    "Summarize(textnep2).count_sentence_nep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.0, 2.44948974, 2.52982215, 3.1622777, 3.20713488, 3.63803444, 3.7712361599999995, 3.7712361599999995, 3.7712361599999995, 3.77964476, 3.87298335, 3.87298335, 4.0249223999999995, 4.12310571, 4.13092191, 4.14613991, 4.24264078, 4.37880262, 4.472136, 4.49073129, 4.49073129, 4.70678735, 4.8493431000000005, 4.91353823]\n",
      " china s thirst for products such as crude oil  copper and steel has helped pushed global commodity prices to record levels||  clearly the chinese are trying to get some leverage [in russia]   said dmitry lukashov  an analyst at brokerage aton||  they understand property rights in russia are not the most important rights  and they are more interested in guaranteeing supplies||   if the price of oil is fixed under the deal  which is unlikely  it could be very profitable for the chinese   mr lukashov continued||\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.41421356, 1.41421356, 1.73205081, 2.236068]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' ब्रोकरेज एटोनका विश्लेषक दिमित्री लुकाशोभले स्पष्ट रूपमा चिनियाँहरूले [रूसमा] केही फाइदा लिन खोजिरहेका छन्|| तिनीहरू बुझ्छन् रसियामा सम्पत्ति अधिकारहरू सबैभन्दा महत्त्वपूर्ण अधिकारहरू होइनन् र तिनीहरू आपूर्तिको ग्यारेन्टीमा बढी चासो राख्छन्|| यदि यो सम्झौता अन्तर्गत तेलको मूल्य निर्धारण गरिएको छ जुन असम्भव छ यो चिनियाँ श्री लुकाशोभको लागि धेरै लाभदायक हुन सक्छ|| र रोस्नेफ्टलाई नगदको असाध्यै आवश्यकता छ त्यसैले यो उनीहरूको लागि पनि राम्रो सम्झौता हो||'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Summarize(texteng2).sentence_number(4))\n",
    "Summarize(textnep2).sentence_number(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nepalipree(nep):\n",
    "    paragraph=nep\n",
    "    paragraph=paragraph.replace(\"।\",\"|\")\n",
    "    each_sentence=paragraph.split(\"|\")\n",
    "    each_sentence.remove(\"\")\n",
    "    each_tfidf=[]\n",
    "    print(each_sentence)\n",
    "    tf_idf_score=[]\n",
    "    for i in range(len(each_sentence)):\n",
    "        each_tfidf.append(Summarize(nep).calc_tf_idf(each_sentence[i]))\n",
    "    for i in range(len(each_tfidf)):\n",
    "        each_tfidf[i]=np.array(each_tfidf[i])\n",
    "        tf_idf_score.append(each_tfidf[i].sum())\n",
    "    print(tf_idf_score)\n",
    "    tf_idf_score=sorted(tf_idf_score)\n",
    "    \n",
    "    selection=tf_idf_score[-4:]\n",
    "    \n",
    "    summarized=\"\"\n",
    "    for i in range(18-1):\n",
    "                for j in range(len(selection)):\n",
    "                    if selection[j]==tf_idf_score[i]:\n",
    "                        summarized += each_sentence[i]\n",
    "                        summarized += \"||\"\n",
    "                        break            \n",
    "    return summarized \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textnep=\"होवार्ड स्नूकर खेल्न आक्रोशित कन्जरभेटिभ नेता माइकल होवार्डले स्नूकर हलमा आफ्ना स्कूलका साथीहरूसँग समय बिताउन ट्रन्ट खेल्ने गरेको स्वीकार गरेका छन्। श्री होवार्डले भने कि 1950 को दशकमा लानेलीको ज्याक स्नूकर हलमा उनको समयले उनलाई कुनै दिगो नोक्सान पुर्याएन। तर उनले टाइम्स शैक्षिक सप्लिमेन्टलाई भने कि ट्र्यान्सी धेरै नराम्रो थियो र दृढ कार्य आवश्यक छ भने। मिस्टर होवर्डले ओ-लेभल र थप कक्षाकोठा अनुशासनमा फर्कन पनि आह्वान गरे। मिस्टर हावर्डले अन्ततः क्याम्ब्रिज विश्वविद्यालय जान लानेली व्याकरण स्कूल र स्नूकर हल छोडे। उसले भन्यो: मलाई लाग्दैन कि यसले मलाई कुनै दिगो नोक्सान गरेको छ। न त यसले मलाई स्नूकर विश्व च्याम्पियन बनाएको छ। हामी दिउँसो छिट्टै निस्किदा केही अवसरहरू भएका हुन सक्छन्। म केवल इमानदार छु। मलाई लाग्छ कि ट्र्यान्सी एक धेरै नराम्रो कुरा हो र यसको सामना गर्न दृढ कदम चाल्नु पर्छ। स्नूकरको विश्व च्याम्पियनसिप जित्न असफल भएका अर्को खेलाडी - जिमी द व्हर्लविन्ड ह्वाइट -ले पहिले आफ्नो दिन धुवाँदार हलहरूमा बिताउनको सट्टा पाठ हराएको स्वीकार गरेका छन्। टोनी मेयो [अर्को खेलाडी] र म हाम्रो सबै खाली समय त्यहाँ बिताउन गर्थ्यौं श्री ह्वाइटले भने कि हामी खेल र वातावरण मन पराउँछौं। विद्यालय झ्यालबाट बाहिर गयो । म केही समयको लागि गएँ र त्यसपछि समय लिन थाले। मिस्टर हावर्डको फेलो वेल्शम्यान रे रीर्डन - जसलाई उनका साथी पेशेवरहरू ड्र्याकुला भनेर चिनिन्छन् - स्नूकर विश्व च्याम्पियनशिप छ पटक जितेका थिए जसले १४ वर्षको उमेरमा स्कूल छोडेर खानीको रूपमा काम गरे। र ल्यानेलीका मिस्टर होवार्ड जस्ता टेरी ग्रिफिथले सन् १९७९ मा प्रतियोगिता जितेका थिए। यी दुईबीच ज्याक एसमा कहिले भिडन्त भएको थियो वा थिएन भन्ने थाहा छैन।\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['होवार्ड स्नूकर खेल्न आक्रोशित कन्जरभेटिभ नेता माइकल होवार्डले स्नूकर हलमा आफ्ना स्कूलका साथीहरूसँग समय बिताउन ट्रन्ट खेल्ने गरेको स्वीकार गरेका छन्', ' श्री होवार्डले भने कि 1950 को दशकमा लानेलीको ज्याक स्नूकर हलमा उनको समयले उनलाई कुनै दिगो नोक्सान पुर्याएन', ' तर उनले टाइम्स शैक्षिक सप्लिमेन्टलाई भने कि ट्र्यान्सी धेरै नराम्रो थियो र दृढ कार्य आवश्यक छ भने', ' मिस्टर होवर्डले ओ-लेभल र थप कक्षाकोठा अनुशासनमा फर्कन पनि आह्वान गरे', ' मिस्टर हावर्डले अन्ततः क्याम्ब्रिज विश्वविद्यालय जान लानेली व्याकरण स्कूल र स्नूकर हल छोडे', ' उसले भन्यो: मलाई लाग्दैन कि यसले मलाई कुनै दिगो नोक्सान गरेको छ', ' न त यसले मलाई स्नूकर विश्व च्याम्पियन बनाएको छ', ' हामी दिउँसो छिट्टै निस्किदा केही अवसरहरू भएका हुन सक्छन्', ' म केवल इमानदार छु', ' मलाई लाग्छ कि ट्र्यान्सी एक धेरै नराम्रो कुरा हो र यसको सामना गर्न दृढ कदम चाल्नु पर्छ', ' स्नूकरको विश्व च्याम्पियनसिप जित्न असफल भएका अर्को खेलाडी - जिमी द व्हर्लविन्ड ह्वाइट -ले पहिले आफ्नो दिन धुवाँदार हलहरूमा बिताउनको सट्टा पाठ हराएको स्वीकार गरेका छन्', ' टोनी मेयो [अर्को खेलाडी] र म हाम्रो सबै खाली समय त्यहाँ बिताउन गर्थ्यौं श्री ह्वाइटले भने कि हामी खेल र वातावरण मन पराउँछौं', ' विद्यालय झ्यालबाट बाहिर गयो ', ' म केही समयको लागि गएँ र त्यसपछि समय लिन थाले', ' मिस्टर हावर्डको फेलो वेल्शम्यान रे रीर्डन - जसलाई उनका साथी पेशेवरहरू ड्र्याकुला भनेर चिनिन्छन् - स्नूकर विश्व च्याम्पियनशिप छ पटक जितेका थिए जसले १४ वर्षको उमेरमा स्कूल छोडेर खानीको रूपमा काम गरे', ' र ल्यानेलीका मिस्टर होवार्ड जस्ता टेरी ग्रिफिथले सन् १९७९ मा प्रतियोगिता जितेका थिए', ' यी दुईबीच ज्याक एसमा कहिले भिडन्त भएको थियो वा थिएन भन्ने थाहा छैन']\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.41421356, 1.0, 1.41421356, 0.0, 1.0, 1.41421356, 1.0, 0.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' न त यसले मलाई स्नूकर विश्व च्याम्पियन बनाएको छ|| हामी दिउँसो छिट्टै निस्किदा केही अवसरहरू भएका हुन सक्छन्|| म केवल इमानदार छु|| मलाई लाग्छ कि ट्र्यान्सी एक धेरै नराम्रो कुरा हो र यसको सामना गर्न दृढ कदम चाल्नु पर्छ|| स्नूकरको विश्व च्याम्पियनसिप जित्न असफल भएका अर्को खेलाडी - जिमी द व्हर्लविन्ड ह्वाइट -ले पहिले आफ्नो दिन धुवाँदार हलहरूमा बिताउनको सट्टा पाठ हराएको स्वीकार गरेका छन्|| टोनी मेयो [अर्को खेलाडी] र म हाम्रो सबै खाली समय त्यहाँ बिताउन गर्थ्यौं श्री ह्वाइटले भने कि हामी खेल र वातावरण मन पराउँछौं|| विद्यालय झ्यालबाट बाहिर गयो || म केही समयको लागि गएँ र त्यसपछि समय लिन थाले|| मिस्टर हावर्डको फेलो वेल्शम्यान रे रीर्डन - जसलाई उनका साथी पेशेवरहरू ड्र्याकुला भनेर चिनिन्छन् - स्नूकर विश्व च्याम्पियनशिप छ पटक जितेका थिए जसले १४ वर्षको उमेरमा स्कूल छोडेर खानीको रूपमा काम गरे|| र ल्यानेलीका मिस्टर होवार्ड जस्ता टेरी ग्रिफिथले सन् १९७९ मा प्रतियोगिता जितेका थिए|| यी दुईबीच ज्याक एसमा कहिले भिडन्त भएको थियो वा थिएन भन्ने थाहा छैन||'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nepalipree(textnep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=vect.fit_transform([textnep])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=x.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04962917, 0.09925833, 0.09925833, 0.04962917, 0.04962917,\n",
       "        0.04962917, 0.09925833, 0.04962917, 0.04962917, 0.04962917,\n",
       "        0.04962917, 0.04962917, 0.09925833, 0.04962917, 0.09925833,\n",
       "        0.1488875 , 0.09925833, 0.04962917, 0.04962917, 0.1488875 ,\n",
       "        0.09925833, 0.04962917, 0.04962917, 0.04962917, 0.09925833,\n",
       "        0.297775  , 0.04962917, 0.04962917, 0.04962917, 0.04962917,\n",
       "        0.04962917, 0.39703333, 0.19851667, 0.04962917, 0.04962917,\n",
       "        0.09925833, 0.19851667, 0.04962917, 0.04962917, 0.09925833,\n",
       "        0.19851667, 0.04962917, 0.04962917, 0.04962917, 0.04962917,\n",
       "        0.04962917, 0.04962917, 0.09925833, 0.04962917, 0.04962917,\n",
       "        0.04962917, 0.09925833, 0.04962917, 0.04962917, 0.04962917,\n",
       "        0.1488875 , 0.34740417, 0.04962917, 0.09925833, 0.19851667,\n",
       "        0.04962917, 0.04962917, 0.04962917, 0.04962917, 0.04962917,\n",
       "        0.04962917, 0.09925833, 0.04962917, 0.04962917, 0.04962917,\n",
       "        0.04962917, 0.04962917, 0.04962917, 0.09925833, 0.04962917,\n",
       "        0.19851667, 0.04962917, 0.04962917, 0.04962917, 0.04962917,\n",
       "        0.04962917, 0.04962917, 0.04962917, 0.04962917, 0.04962917,\n",
       "        0.04962917, 0.04962917, 0.04962917, 0.1488875 , 0.04962917,\n",
       "        0.04962917, 0.1488875 , 0.04962917, 0.09925833, 0.04962917,\n",
       "        0.04962917, 0.04962917]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=['होवार्ड स्नूकर खेल्न आक्रोशित कन्जरभेटिभ नेता माइकल होवार्डले स्नूकर हलमा आफ्ना स्कूलका साथीहरूसँग समय बिताउन ट्रन्ट खेल्ने गरेको स्वीकार गरेका छन्', ' श्री होवार्डले भने कि 1950 को दशकमा लानेलीको ज्याक स्नूकर हलमा उनको समयले उनलाई कुनै दिगो नोक्सान पुर्याएन', ' तर उनले टाइम्स शैक्षिक सप्लिमेन्टलाई भने कि ट्र्यान्सी धेरै नराम्रो थियो र दृढ कार्य आवश्यक छ भने']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum = Summarize(corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum.calc_tf_idf(corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus[0].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv = {}\n",
    "for t in corpus[0].split():\n",
    "    if t not in tv.keys():\n",
    "        tv[t] = 1\n",
    "    else:\n",
    "        tv[t] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'होवार्ड': 1,\n",
       " 'स्नूकर': 2,\n",
       " 'खेल्न': 1,\n",
       " 'आक्रोशित': 1,\n",
       " 'कन्जरभेटिभ': 1,\n",
       " 'नेता': 1,\n",
       " 'माइकल': 1,\n",
       " 'होवार्डले': 1,\n",
       " 'हलमा': 1,\n",
       " 'आफ्ना': 1,\n",
       " 'स्कूलका': 1,\n",
       " 'साथीहरूसँग': 1,\n",
       " 'समय': 1,\n",
       " 'बिताउन': 1,\n",
       " 'ट्रन्ट': 1,\n",
       " 'खेल्ने': 1,\n",
       " 'गरेको': 1,\n",
       " 'स्वीकार': 1,\n",
       " 'गरेका': 1,\n",
       " 'छन्': 1}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1950', 'आक', 'आफ', 'आवश', 'इकल', 'इम', 'उन', 'उनक', 'उनल', 'एन',\n",
       "       'कन', 'कर', 'गर', 'छन', 'जरभ', 'टल', 'डल', 'तर', 'दशकम', 'नर',\n",
       "       'भन', 'यक', 'रन', 'लक', 'सप', 'समय', 'समयल', 'हर', 'हलम'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "X = tfidf_vectorizer.fit_transform(corpus)\n",
    "tfidf_vectorizer.get_feature_names_out()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 29)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ['howard  truanted to play snooker  conservative leader michael howard has admitted he used to play truant to spend time with his school friends at a snooker hall.','mr howard said his time at jack s  snooker hall in llanelli in the 1950s had not done him  any lasting damage.','but he told the times educational supplement that truancy was  very bad  and said  firm action  was needed.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1950s', 'action', 'admitted', 'and', 'any', 'at', 'bad', 'but',\n",
       "       'conservative', 'damage', 'done', 'educational', 'firm', 'friends',\n",
       "       'had', 'hall', 'has', 'he', 'him', 'his', 'howard', 'in', 'jack',\n",
       "       'lasting', 'leader', 'llanelli', 'michael', 'mr', 'needed', 'not',\n",
       "       'play', 'said', 'school', 'snooker', 'spend', 'supplement', 'that',\n",
       "       'the', 'time', 'times', 'to', 'told', 'truancy', 'truant',\n",
       "       'truanted', 'used', 'very', 'was', 'with'], dtype=object)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tfidf_vectorizer.fit_transform(corpus)\n",
    "tfidf_vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 49)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes\n"
     ]
    }
   ],
   "source": [
    "if 'होवार्ड' == 'होवार्ड':\n",
    "    print('Yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "होवार्ड\n"
     ]
    }
   ],
   "source": [
    "print('होवार्ड')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SummarizeCheck:\n",
    "    def __init__(self,paragraph):\n",
    "        self.paragraph=paragraph\n",
    "        self.language=detect(self.paragraph)\n",
    "        if detect(self.language) != \"en\":\n",
    "            #stop_words\n",
    "            self.stop_words=open(\"stopwords.txt\",\"r\",encoding=\"utf-8\")\n",
    "            self.stop_words=self.stop_words.read()\n",
    "            self.stop_words=self.stop_words.split(\"\\n\")\n",
    "            \n",
    "            #num file\n",
    "            self.nepali_num=open(\"numbers.txt\",\"r\",encoding=\"utf-8\")\n",
    "            self.nepali_num=self.nepali_num.read()\n",
    "            self.nepali_num=self.nepali_num.split(\",\")\n",
    "            \n",
    "            #suffix file\n",
    "            self.nepali_suffix=open(\"suffix.txt\",\"r\",encoding=\"utf-8\")\n",
    "            self.nepali_suffix=self.nepali_suffix.read()\n",
    "            self.nepali_suffix=self.nepali_suffix.split(\"\\n\")\n",
    "            \n",
    "            self.paragraph = self.nepali_process_paragraph()\n",
    "        else:\n",
    "            self.paragraph = self.english_process_paragraph()\n",
    "        self.col=[]\n",
    "        for t in paragraph.split():\n",
    "            if t not in self.col:\n",
    "                self.col.append(t)\n",
    "    \n",
    "    def nepali_process_paragraph(self):\n",
    "        paragraph=str(self.paragraph)\n",
    "        \n",
    "        #removing \\n and \\ufeff\n",
    "        remove=['\\n','\\ufeff']\n",
    "        for i in remove:\n",
    "            paragraph.replace(i,'')\n",
    "        \n",
    "        #read stop words\n",
    "        #Remove Stop Words\n",
    "        #word_tokens = Tokenizer().word_tokenize(text)\n",
    "        word_tokens = paragraph.split(\" \")\n",
    "        filtered_list = [w for w in word_tokens if not w in self.stop_words]\n",
    "        \n",
    "        #Remove Nepali numbers\n",
    "        num_filter=[]\n",
    "        for i in range(0,len(filtered_list)):\n",
    "            for j in range(0,len(self.nepali_num)):\n",
    "                if self.nepali_num[j] in filtered_list[i]:\n",
    "                    num_filter.append(filtered_list[i])\n",
    "                    break\n",
    "        for filter in num_filter:\n",
    "            filtered_list.remove(filter)\n",
    "        \n",
    "        #Remove English numbers\n",
    "        num=['0','1','2','3','4','5','6','7','8','9']\n",
    "        num_filter=[]\n",
    "        for i in range(0,len(filtered_list)):\n",
    "            for j in range(0,len(num)):\n",
    "                if num[j] in filtered_list[i]:\n",
    "                    num_filter.append(filtered_list[i])\n",
    "                    break\n",
    "        for filter in num_filter:\n",
    "            filtered_list.remove(filter)\n",
    "        stemmed_string=' '.join(filtered_list)\n",
    "        \n",
    "        return stemmed_string\n",
    "            \n",
    "    def english_process_paragraph(self):\n",
    "        paragraph=str(self.paragraph)\n",
    "        #lowercasing\n",
    "        paragraph=paragraph.lower()\n",
    "        #Remove Stop Words\n",
    "        stop_words=set(stopwords.words('english'))\n",
    "        word_tokens = word_tokenize(paragraph)\n",
    "        filtered_list = [w for w in word_tokens if not w in stop_words]\n",
    "        \n",
    "        \n",
    "        #Remove numbers and special Symbols\n",
    "        #words like 100m 2m were not removed so using this\n",
    "        num=['0','1','2','3','4','5','6','7','8','9']\n",
    "        num_filter=[]\n",
    "        for i in range(0,len(filtered_list)):\n",
    "            for j in range(0,len(num)):\n",
    "                if num[j] in filtered_list[i]:\n",
    "                    num_filter.append(filtered_list[i])\n",
    "                    break\n",
    "        \n",
    "        for filter in num_filter:\n",
    "            filtered_list.remove(filter)\n",
    "                    \n",
    "        filtered_list = [w for w in filtered_list if w.isalnum()]\n",
    "        \n",
    "        #Lematizing\n",
    "        wordnet_lemmatizer=WordNetLemmatizer()\n",
    "        lemmatized_list=[wordnet_lemmatizer.lemmatize(w,wordnet.VERB) for w in filtered_list]\n",
    "        lemmatized_string=' '.join(lemmatized_list)\n",
    "        \n",
    "        return lemmatized_string\n",
    "    \n",
    "    def calc_idf(self):\n",
    "        doc_count=len(self.paragraph)\n",
    "        df={}\n",
    "        idf={}\n",
    "        for char in self.col:\n",
    "            df[char]=0\n",
    "            idf[char]=0\n",
    "        #Calculating df\n",
    "        for i in range(0,len(self.col)):\n",
    "            for j in range(0,len(self.paragraph)):\n",
    "                if self.col[i] in self.paragraph[j]:\n",
    "                    df[self.col[i]]+=1\n",
    "        #Calculating idf\n",
    "        for char in self.col:\n",
    "            idf[char]=math.log((doc_count+1)/(1+df[char]))+1\n",
    "        return(idf)\n",
    "    \n",
    "    def calc_tf_idf(self,sentence):\n",
    "        idf=self.calc_idf()\n",
    "        \n",
    "        tf_idf={}\n",
    "        word_count={}\n",
    "    \n",
    "        for ch in self.col:\n",
    "            tf_idf[ch]=0\n",
    "            word_count[ch]=0\n",
    "        #Calculating tf\n",
    "        words = sentence.split()\n",
    "        for ch in words:\n",
    "            if ch in self.col:\n",
    "                if ch in word_count:\n",
    "                    word_count[ch] += 1\n",
    "                else:\n",
    "                    word_count[ch] = 1\n",
    "    \n",
    "        rough_tfidf=list(self.col)\n",
    "        for keys in word_count.keys():\n",
    "            tf_idf[keys]=idf[keys]*word_count[keys]\n",
    "            if keys in rough_tfidf:\n",
    "                index=rough_tfidf.index(keys)\n",
    "                rough_tfidf[index]=tf_idf[keys]\n",
    "        norm=0\n",
    "        for i in range(0,len(rough_tfidf)):\n",
    "            norm+=rough_tfidf[i]**2\n",
    "        if norm==0:\n",
    "            norm=1\n",
    "        for i in range(0,len(rough_tfidf)):\n",
    "            rough_tfidf[i]=round(rough_tfidf[i]/math.sqrt(norm),8)\n",
    "        return rough_tfidf\n",
    "    \n",
    "    def count_sentence_eng(self):\n",
    "        cnt=self.paragraph.count(\".\")+1\n",
    "        return cnt\n",
    "    def count_sentence_nep(self):\n",
    "        cnt=self.paragraph.count(\"।\")+1\n",
    "        return cnt\n",
    "    def count_summarized(self,summarized):\n",
    "        cnt=summarized.count(\"||\")+1\n",
    "        return cnt\n",
    "    \n",
    "    def sentence_number(self,number):\n",
    "        paragraph=self.paragraph\n",
    "        \n",
    "        if self.language==\"en\":\n",
    "            processed_paragraph=self.english_process_paragraph()\n",
    "            each_sentence=paragraph.split(\".\")\n",
    "            each_sentence.remove(\"\")\n",
    "            sentence_count=self.count_sentence_eng()\n",
    "        else:\n",
    "            processed_paragraph=self.nepali_process_paragraph()\n",
    "            #paragraph=paragraph.replace(\"।\",\"|\")\n",
    "            each_sentence=paragraph.split(\"।\")\n",
    "            each_sentence.remove(\"\")\n",
    "            sentence_count=self.count_sentence_nep()\n",
    "            \n",
    "        \n",
    "        if (number>sentence_count):\n",
    "            print(\"ERROR: Summarization line exceeds total sentence count\")\n",
    "        \n",
    "        else:\n",
    "            #Each sentence tf_idf\n",
    "            each_tfidf=[]\n",
    "            tf_idf_score=[]\n",
    "            for i in range(len(each_sentence)):\n",
    "                each_tfidf.append(self.calc_tf_idf(each_sentence[i]))\n",
    "            for i in range(len(each_tfidf)):\n",
    "                each_tfidf[i]=np.array(each_tfidf[i])\n",
    "                tf_idf_score.append(each_tfidf[i].sum())\n",
    "            \n",
    "            tf_idf_score=sorted(tf_idf_score)\n",
    "            print(tf_idf_score)\n",
    "            selection=tf_idf_score[-number:]\n",
    "            \n",
    "            summarized=\"\"\n",
    "            for i in range(sentence_count-1):\n",
    "                for j in range(len(selection)-1,-1,-1):\n",
    "                    if selection[j]==tf_idf_score[i]:\n",
    "                        summarized += each_sentence[i]\n",
    "                        summarized += \"||\"\n",
    "                        break\n",
    "                if self.count_summarized(summarized)==number+1:\n",
    "                    break\n",
    "                           \n",
    "            return summarized \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "textnep=\"होवार्ड स्नूकर खेल्न आक्रोशित कन्जरभेटिभ नेता माइकल होवार्डले स्नूकर हलमा आफ्ना स्कूलका साथीहरूसँग समय बिताउन ट्रन्ट खेल्ने गरेको स्वीकार गरेका छन्। श्री होवार्डले भने कि 1950 को दशकमा लानेलीको ज्याक स्नूकर हलमा उनको समयले उनलाई कुनै दिगो नोक्सान पुर्याएन। तर उनले टाइम्स शैक्षिक सप्लिमेन्टलाई भने कि ट्र्यान्सी धेरै नराम्रो थियो र दृढ कार्य आवश्यक छ भने। मिस्टर होवर्डले ओ-लेभल र थप कक्षाकोठा अनुशासनमा फर्कन पनि आह्वान गरे। मिस्टर हावर्डले अन्ततः क्याम्ब्रिज विश्वविद्यालय जान लानेली व्याकरण स्कूल र स्नूकर हल छोडे। उसले भन्यो: मलाई लाग्दैन कि यसले मलाई कुनै दिगो नोक्सान गरेको छ। न त यसले मलाई स्नूकर विश्व च्याम्पियन बनाएको छ। हामी दिउँसो छिट्टै निस्किदा केही अवसरहरू भएका हुन सक्छन्। म केवल इमानदार छु। मलाई लाग्छ कि ट्र्यान्सी एक धेरै नराम्रो कुरा हो र यसको सामना गर्न दृढ कदम चाल्नु पर्छ। स्नूकरको विश्व च्याम्पियनसिप जित्न असफल भएका अर्को खेलाडी - जिमी द व्हर्लविन्ड ह्वाइट -ले पहिले आफ्नो दिन धुवाँदार हलहरूमा बिताउनको सट्टा पाठ हराएको स्वीकार गरेका छन्। टोनी मेयो [अर्को खेलाडी] र म हाम्रो सबै खाली समय त्यहाँ बिताउन गर्थ्यौं श्री ह्वाइटले भने कि हामी खेल र वातावरण मन पराउँछौं। विद्यालय झ्यालबाट बाहिर गयो । म केही समयको लागि गएँ र त्यसपछि समय लिन थाले। मिस्टर हावर्डको फेलो वेल्शम्यान रे रीर्डन - जसलाई उनका साथी पेशेवरहरू ड्र्याकुला भनेर चिनिन्छन् - स्नूकर विश्व च्याम्पियनशिप छ पटक जितेका थिए जसले १४ वर्षको उमेरमा स्कूल छोडेर खानीको रूपमा काम गरे। र ल्यानेलीका मिस्टर होवार्ड जस्ता टेरी ग्रिफिथले सन् १९७९ मा प्रतियोगिता जितेका थिए। यी दुईबीच ज्याक एसमा कहिले भिडन्त भएको थियो वा थिएन भन्ने थाहा छैन।\"\n",
    "texteng=\"howard  truanted to play snooker  conservative leader michael howard has admitted he used to play truant to spend time with his school friends at a snooker hall.  mr howard said his time at jack s snooker hall in llanelli in the 1950s had not done him  any lasting damage . but he told the times educational supplement that truancy was  very bad  and said  firm action  was needed. mr howard also called for a return to o-levels and more classroom discipline.  mr howard eventually left llanelli grammar school - and the snooker hall - to go to cambridge university. he said:  i don t think it s done me any lasting damage. nor has it made me a snooker world champion.  there might have been some occasions when we left early of an afternoon.   i m just being honest. i think truancy is a very bad thing and that firm action should be taken to deal with it.  another player who has failed to win snooker s world championship - jimmy  the whirlwind   white - has previously admitted missing lessons  instead spending his days in smoky halls.  tony meo [another player] and me used to spend all of our spare time there   mr white said   we loved the game and the atmosphere.  school went out of the window. i went for a while and then started taking time off.  mr howard s fellow welshman ray reardon - known by his fellow professionals as  dracula  - won the snooker world championship six times  having left school at 14 to work as a miner. and terry griffiths  like mr howard from llanelli  won the tournament in 1979. it is not known whether the two of them ever clashed cues at jack s.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.89696827, 2.236068, 2.77242604, 3.06972982, 3.4180914099999997, 3.46410156, 3.49103474, 3.76052862, 3.90006742, 4.27740487, 4.2904784099999995, 4.34282796, 4.53557374, 4.96816152, 4.983054790000001, 5.068206870000001]\n",
      "  tony meo [another player] and me used to spend all of our spare time there   mr white said   we loved the game and the atmosphere||  school went out of the window|| i went for a while and then started taking time off||  mr howard s fellow welshman ray reardon - known by his fellow professionals as  dracula  - won the snooker world championship six times  having left school at to work as a miner|| and terry griffiths  like mr howard from llanelli  won the tournament in it is not known whether the two of them ever clashed cues at jack s||\n",
      "[1.41421356, 1.73205081, 2.0, 2.0, 2.2118760699999997, 2.21187607, 2.236068, 2.6457512899999998, 2.6457512899999998, 2.99999997, 2.99999997, 3.1622776999999997, 3.1622777, 3.4641015600000005, 3.90006742, 4.22379773, 4.55261084]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' विद्यालय झ्यालबाट गयो || समयको गएँ त्यसपछि लिन थाले|| मिस्टर हावर्डको फेलो वेल्शम्यान रीर्डन - उनका साथी पेशेवरहरू ड्र्याकुला चिनिन्छन् - स्नूकर विश्व च्याम्पियनशिप जितेका वर्षको उमेरमा स्कूल छोडेर खानीको रूपमा गरे|| ल्यानेलीका मिस्टर होवार्ड टेरी ग्रिफिथले सन् प्रतियोगिता जितेका थिए|| दुईबीच ज्याक एसमा कहिले भिडन्त छैन||'"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(SummarizeCheck(texteng).sentence_number(5))\n",
    "SummarizeCheck(textnep).sentence_number(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "news",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "54d7853ee6fa0f00287d6366039c823ef0d7deed99bd833d3ec41cd5f7adce9b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
